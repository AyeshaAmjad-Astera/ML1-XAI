{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flaml in c:\\users\\ayesha.amjad\\appdata\\local\\anaconda3\\lib\\site-packages (1.2.1)\n",
      "Requirement already satisfied: NumPy>=1.17.0rc1 in c:\\users\\ayesha.amjad\\appdata\\local\\anaconda3\\lib\\site-packages (from flaml) (1.23.5)\n",
      "Requirement already satisfied: lightgbm>=2.3.1 in c:\\users\\ayesha.amjad\\appdata\\roaming\\python\\python310\\site-packages (from flaml) (3.3.5)\n",
      "Requirement already satisfied: xgboost>=0.90 in c:\\users\\ayesha.amjad\\appdata\\roaming\\python\\python310\\site-packages (from flaml) (1.7.5)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\ayesha.amjad\\appdata\\local\\anaconda3\\lib\\site-packages (from flaml) (1.10.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\ayesha.amjad\\appdata\\local\\anaconda3\\lib\\site-packages (from flaml) (1.5.3)\n",
      "Requirement already satisfied: scikit-learn>=0.24 in c:\\users\\ayesha.amjad\\appdata\\roaming\\python\\python310\\site-packages (from flaml) (1.2.2)\n",
      "Requirement already satisfied: wheel in c:\\users\\ayesha.amjad\\appdata\\local\\anaconda3\\lib\\site-packages (from lightgbm>=2.3.1->flaml) (0.38.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\ayesha.amjad\\appdata\\local\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->flaml) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ayesha.amjad\\appdata\\local\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->flaml) (2022.7)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\ayesha.amjad\\appdata\\local\\anaconda3\\lib\\site-packages (from scikit-learn>=0.24->flaml) (1.1.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\ayesha.amjad\\appdata\\local\\anaconda3\\lib\\site-packages (from scikit-learn>=0.24->flaml) (2.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ayesha.amjad\\appdata\\local\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas>=1.1.4->flaml) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#pip install flaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np   \n",
    "import time\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split #, RepeatedKFold, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flaml import AutoML\n",
    "from flaml.data import get_output_from_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import pandas as pd\n",
    "from utils.data_utils import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(file_path='../data/raw/Churn_Modelling.xls' , target_column='Exited', test_size=0.2, random_state=42, clean_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9867 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore Geography  Gender  Age Tenure    Balance NumOfProducts  \\\n",
       "0             619    France  Female   42      2       0.00             1   \n",
       "1             608     Spain  Female   41      1   83807.86             1   \n",
       "2             502    France  Female   42      8  159660.80             3   \n",
       "3             699    France  Female   39      1       0.00             2   \n",
       "4             850     Spain  Female   43      2  125510.82             1   \n",
       "...           ...       ...     ...  ...    ...        ...           ...   \n",
       "9995          771    France    Male   39      5       0.00             2   \n",
       "9996          516    France    Male   35     10   57369.61             1   \n",
       "9997          709    France  Female   36      7       0.00             1   \n",
       "9998          772   Germany    Male   42      3   75075.31             2   \n",
       "9999          792    France  Female   28      4  130142.79             1   \n",
       "\n",
       "     HasCrCard IsActiveMember  EstimatedSalary  Exited  \n",
       "0            1              1        101348.88       1  \n",
       "1            0              1        112542.58       0  \n",
       "2            1              0        113931.57       1  \n",
       "3            0              0         93826.63       0  \n",
       "4            1              1         79084.10       0  \n",
       "...        ...            ...              ...     ...  \n",
       "9995         1              0         96270.64       0  \n",
       "9996         1              1        101699.77       0  \n",
       "9997         0              1         42085.58       1  \n",
       "9998         1              0         92888.52       1  \n",
       "9999         1              0         38190.78       0  \n",
       "\n",
       "[9867 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data_loader.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = data_loader.get_train_data()\n",
    "X_test, y_test = data_loader.get_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl = AutoML()\n",
    "automl_settings = {\n",
    "    \"time_budget\": 200,\n",
    "    \"metric\": 'roc_auc',\n",
    "    \"task\": 'classification',\n",
    "    \"log_file_name\": 'automl.log',\n",
    "    \"model_history\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 05-28 12:15:11] {1682} INFO - task = classification\n",
      "[flaml.automl.logger: 05-28 12:15:11] {1689} INFO - Data split method: stratified\n",
      "[flaml.automl.logger: 05-28 12:15:11] {1692} INFO - Evaluation method: cv\n",
      "[flaml.automl.logger: 05-28 12:15:11] {1790} INFO - Minimizing error metric: 1-roc_auc\n",
      "[flaml.automl.logger: 05-28 12:15:11] {1900} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'catboost', 'xgboost', 'extra_tree', 'xgb_limitdepth', 'lrl1']\n",
      "[flaml.automl.logger: 05-28 12:15:11] {2210} INFO - iteration 0, current learner lgbm\n",
      "[flaml.automl.logger: 05-28 12:15:11] {2336} INFO - Estimated sufficient time budget=2107s. Estimated necessary time budget=52s.\n",
      "[flaml.automl.logger: 05-28 12:15:11] {2383} INFO -  at 0.4s,\testimator lgbm's best error=0.1904,\tbest estimator lgbm's best error=0.1904\n",
      "[flaml.automl.logger: 05-28 12:15:11] {2210} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl.logger: 05-28 12:15:12] {2383} INFO -  at 0.6s,\testimator lgbm's best error=0.1904,\tbest estimator lgbm's best error=0.1904\n",
      "[flaml.automl.logger: 05-28 12:15:12] {2210} INFO - iteration 2, current learner lgbm\n",
      "[flaml.automl.logger: 05-28 12:15:12] {2383} INFO -  at 0.7s,\testimator lgbm's best error=0.1755,\tbest estimator lgbm's best error=0.1755\n",
      "[flaml.automl.logger: 05-28 12:15:12] {2210} INFO - iteration 3, current learner lgbm\n",
      "[flaml.automl.logger: 05-28 12:15:12] {2383} INFO -  at 0.9s,\testimator lgbm's best error=0.1465,\tbest estimator lgbm's best error=0.1465\n",
      "[flaml.automl.logger: 05-28 12:15:12] {2210} INFO - iteration 4, current learner lgbm\n",
      "[flaml.automl.logger: 05-28 12:15:12] {2383} INFO -  at 1.0s,\testimator lgbm's best error=0.1465,\tbest estimator lgbm's best error=0.1465\n",
      "[flaml.automl.logger: 05-28 12:15:12] {2210} INFO - iteration 5, current learner lgbm\n",
      "[flaml.automl.logger: 05-28 12:15:12] {2383} INFO -  at 1.2s,\testimator lgbm's best error=0.1447,\tbest estimator lgbm's best error=0.1447\n",
      "[flaml.automl.logger: 05-28 12:15:12] {2210} INFO - iteration 6, current learner lgbm\n",
      "[flaml.automl.logger: 05-28 12:15:12] {2383} INFO -  at 1.3s,\testimator lgbm's best error=0.1447,\tbest estimator lgbm's best error=0.1447\n",
      "[flaml.automl.logger: 05-28 12:15:12] {2210} INFO - iteration 7, current learner lgbm\n",
      "[flaml.automl.logger: 05-28 12:15:12] {2383} INFO -  at 1.5s,\testimator lgbm's best error=0.1447,\tbest estimator lgbm's best error=0.1447\n",
      "[flaml.automl.logger: 05-28 12:15:12] {2210} INFO - iteration 8, current learner lgbm\n",
      "[flaml.automl.logger: 05-28 12:15:13] {2383} INFO -  at 1.7s,\testimator lgbm's best error=0.1410,\tbest estimator lgbm's best error=0.1410\n",
      "[flaml.automl.logger: 05-28 12:15:13] {2210} INFO - iteration 9, current learner xgboost\n",
      "[flaml.automl.logger: 05-28 12:15:13] {2383} INFO -  at 2.0s,\testimator xgboost's best error=0.2381,\tbest estimator lgbm's best error=0.1410\n",
      "[flaml.automl.logger: 05-28 12:15:13] {2210} INFO - iteration 10, current learner xgboost\n",
      "[flaml.automl.logger: 05-28 12:15:13] {2383} INFO -  at 2.2s,\testimator xgboost's best error=0.2272,\tbest estimator lgbm's best error=0.1410\n",
      "[flaml.automl.logger: 05-28 12:15:13] {2210} INFO - iteration 11, current learner extra_tree\n",
      "[flaml.automl.logger: 05-28 12:15:13] {2383} INFO -  at 2.5s,\testimator extra_tree's best error=0.2324,\tbest estimator lgbm's best error=0.1410\n",
      "[flaml.automl.logger: 05-28 12:15:13] {2210} INFO - iteration 12, current learner extra_tree\n",
      "[flaml.automl.logger: 05-28 12:15:14] {2383} INFO -  at 2.7s,\testimator extra_tree's best error=0.1835,\tbest estimator lgbm's best error=0.1410\n",
      "[flaml.automl.logger: 05-28 12:15:14] {2210} INFO - iteration 13, current learner lgbm\n",
      "[flaml.automl.logger: 05-28 12:15:14] {2383} INFO -  at 2.9s,\testimator lgbm's best error=0.1410,\tbest estimator lgbm's best error=0.1410\n",
      "[flaml.automl.logger: 05-28 12:15:14] {2210} INFO - iteration 14, current learner extra_tree\n",
      "[flaml.automl.logger: 05-28 12:15:14] {2383} INFO -  at 3.2s,\testimator extra_tree's best error=0.1835,\tbest estimator lgbm's best error=0.1410\n",
      "[flaml.automl.logger: 05-28 12:15:14] {2210} INFO - iteration 15, current learner rf\n",
      "[flaml.automl.logger: 05-28 12:15:14] {2383} INFO -  at 3.4s,\testimator rf's best error=0.2034,\tbest estimator lgbm's best error=0.1410\n",
      "[flaml.automl.logger: 05-28 12:15:14] {2210} INFO - iteration 16, current learner lgbm\n",
      "[flaml.automl.logger: 05-28 12:15:15] {2383} INFO -  at 4.0s,\testimator lgbm's best error=0.1410,\tbest estimator lgbm's best error=0.1410\n",
      "[flaml.automl.logger: 05-28 12:15:15] {2210} INFO - iteration 17, current learner extra_tree\n",
      "[flaml.automl.logger: 05-28 12:15:15] {2383} INFO -  at 4.4s,\testimator extra_tree's best error=0.1835,\tbest estimator lgbm's best error=0.1410\n",
      "[flaml.automl.logger: 05-28 12:15:15] {2210} INFO - iteration 18, current learner lgbm\n",
      "[flaml.automl.logger: 05-28 12:15:16] {2383} INFO -  at 4.8s,\testimator lgbm's best error=0.1410,\tbest estimator lgbm's best error=0.1410\n",
      "[flaml.automl.logger: 05-28 12:15:16] {2210} INFO - iteration 19, current learner rf\n",
      "[flaml.automl.logger: 05-28 12:15:16] {2383} INFO -  at 5.1s,\testimator rf's best error=0.1663,\tbest estimator lgbm's best error=0.1410\n",
      "[flaml.automl.logger: 05-28 12:15:16] {2210} INFO - iteration 20, current learner rf\n",
      "[flaml.automl.logger: 05-28 12:15:16] {2383} INFO -  at 5.3s,\testimator rf's best error=0.1663,\tbest estimator lgbm's best error=0.1410\n",
      "[flaml.automl.logger: 05-28 12:15:16] {2210} INFO - iteration 21, current learner rf\n",
      "[flaml.automl.logger: 05-28 12:15:17] {2383} INFO -  at 5.7s,\testimator rf's best error=0.1663,\tbest estimator lgbm's best error=0.1410\n",
      "[flaml.automl.logger: 05-28 12:15:17] {2210} INFO - iteration 22, current learner lgbm\n",
      "[flaml.automl.logger: 05-28 12:15:17] {2383} INFO -  at 5.9s,\testimator lgbm's best error=0.1410,\tbest estimator lgbm's best error=0.1410\n",
      "[flaml.automl.logger: 05-28 12:15:17] {2210} INFO - iteration 23, current learner lgbm\n",
      "[flaml.automl.logger: 05-28 12:15:17] {2383} INFO -  at 6.3s,\testimator lgbm's best error=0.1410,\tbest estimator lgbm's best error=0.1410\n",
      "[flaml.automl.logger: 05-28 12:15:17] {2210} INFO - iteration 24, current learner extra_tree\n",
      "[flaml.automl.logger: 05-28 12:15:18] {2383} INFO -  at 6.5s,\testimator extra_tree's best error=0.1830,\tbest estimator lgbm's best error=0.1410\n",
      "[flaml.automl.logger: 05-28 12:15:18] {2210} INFO - iteration 25, current learner xgboost\n",
      "[flaml.automl.logger: 05-28 12:15:18] {2383} INFO -  at 6.8s,\testimator xgboost's best error=0.2272,\tbest estimator lgbm's best error=0.1410\n",
      "[flaml.automl.logger: 05-28 12:15:18] {2210} INFO - iteration 26, current learner lgbm\n",
      "[flaml.automl.logger: 05-28 12:15:18] {2383} INFO -  at 7.1s,\testimator lgbm's best error=0.1388,\tbest estimator lgbm's best error=0.1388\n",
      "[flaml.automl.logger: 05-28 12:15:18] {2210} INFO - iteration 27, current learner rf\n",
      "[flaml.automl.logger: 05-28 12:15:19] {2383} INFO -  at 7.6s,\testimator rf's best error=0.1663,\tbest estimator lgbm's best error=0.1388\n",
      "[flaml.automl.logger: 05-28 12:15:19] {2210} INFO - iteration 28, current learner rf\n",
      "[flaml.automl.logger: 05-28 12:15:19] {2383} INFO -  at 8.0s,\testimator rf's best error=0.1624,\tbest estimator lgbm's best error=0.1388\n",
      "[flaml.automl.logger: 05-28 12:15:19] {2210} INFO - iteration 29, current learner xgboost\n",
      "[flaml.automl.logger: 05-28 12:15:19] {2383} INFO -  at 8.2s,\testimator xgboost's best error=0.1974,\tbest estimator lgbm's best error=0.1388\n",
      "[flaml.automl.logger: 05-28 12:15:19] {2210} INFO - iteration 30, current learner lgbm\n",
      "[flaml.automl.logger: 05-28 12:15:20] {2383} INFO -  at 8.7s,\testimator lgbm's best error=0.1388,\tbest estimator lgbm's best error=0.1388\n",
      "[flaml.automl.logger: 05-28 12:15:20] {2210} INFO - iteration 31, current learner lgbm\n",
      "[flaml.automl.logger: 05-28 12:15:20] {2383} INFO -  at 9.0s,\testimator lgbm's best error=0.1388,\tbest estimator lgbm's best error=0.1388\n",
      "[flaml.automl.logger: 05-28 12:15:20] {2210} INFO - iteration 32, current learner lgbm\n",
      "[flaml.automl.logger: 05-28 12:15:20] {2383} INFO -  at 9.5s,\testimator lgbm's best error=0.1388,\tbest estimator lgbm's best error=0.1388\n",
      "[flaml.automl.logger: 05-28 12:15:20] {2210} INFO - iteration 33, current learner xgboost\n",
      "[flaml.automl.logger: 05-28 12:15:21] {2383} INFO -  at 9.8s,\testimator xgboost's best error=0.1814,\tbest estimator lgbm's best error=0.1388\n",
      "[flaml.automl.logger: 05-28 12:15:21] {2210} INFO - iteration 34, current learner lgbm\n",
      "[flaml.automl.logger: 05-28 12:15:21] {2383} INFO -  at 10.1s,\testimator lgbm's best error=0.1388,\tbest estimator lgbm's best error=0.1388\n",
      "[flaml.automl.logger: 05-28 12:15:21] {2210} INFO - iteration 35, current learner rf\n",
      "[flaml.automl.logger: 05-28 12:15:22] {2383} INFO -  at 10.6s,\testimator rf's best error=0.1624,\tbest estimator lgbm's best error=0.1388\n",
      "[flaml.automl.logger: 05-28 12:15:22] {2210} INFO - iteration 36, current learner xgboost\n",
      "[flaml.automl.logger: 05-28 12:15:22] {2383} INFO -  at 10.8s,\testimator xgboost's best error=0.1759,\tbest estimator lgbm's best error=0.1388\n",
      "[flaml.automl.logger: 05-28 12:15:22] {2210} INFO - iteration 37, current learner lgbm\n",
      "[flaml.automl.logger: 05-28 12:15:22] {2383} INFO -  at 11.0s,\testimator lgbm's best error=0.1388,\tbest estimator lgbm's best error=0.1388\n",
      "[flaml.automl.logger: 05-28 12:15:22] {2210} INFO - iteration 38, current learner xgboost\n",
      "[flaml.automl.logger: 05-28 12:15:22] {2383} INFO -  at 11.3s,\testimator xgboost's best error=0.1742,\tbest estimator lgbm's best error=0.1388\n",
      "[flaml.automl.logger: 05-28 12:15:22] {2210} INFO - iteration 39, current learner lgbm\n",
      "[flaml.automl.logger: 05-28 12:15:23] {2383} INFO -  at 11.9s,\testimator lgbm's best error=0.1388,\tbest estimator lgbm's best error=0.1388\n",
      "[flaml.automl.logger: 05-28 12:15:23] {2210} INFO - iteration 40, current learner lgbm\n",
      "[flaml.automl.logger: 05-28 12:15:23] {2383} INFO -  at 12.2s,\testimator lgbm's best error=0.1388,\tbest estimator lgbm's best error=0.1388\n",
      "[flaml.automl.logger: 05-28 12:15:23] {2210} INFO - iteration 41, current learner xgboost\n",
      "[flaml.automl.logger: 05-28 12:15:24] {2383} INFO -  at 12.6s,\testimator xgboost's best error=0.1635,\tbest estimator lgbm's best error=0.1388\n",
      "[flaml.automl.logger: 05-28 12:15:24] {2210} INFO - iteration 42, current learner lgbm\n",
      "[flaml.automl.logger: 05-28 12:15:24] {2383} INFO -  at 12.9s,\testimator lgbm's best error=0.1388,\tbest estimator lgbm's best error=0.1388\n",
      "[flaml.automl.logger: 05-28 12:15:24] {2210} INFO - iteration 43, current learner xgboost\n",
      "[flaml.automl.logger: 05-28 12:15:24] {2383} INFO -  at 13.2s,\testimator xgboost's best error=0.1635,\tbest estimator lgbm's best error=0.1388\n",
      "[flaml.automl.logger: 05-28 12:15:24] {2210} INFO - iteration 44, current learner xgboost\n",
      "[flaml.automl.logger: 05-28 12:15:25] {2383} INFO -  at 13.6s,\testimator xgboost's best error=0.1589,\tbest estimator lgbm's best error=0.1388\n",
      "[flaml.automl.logger: 05-28 12:15:25] {2210} INFO - iteration 45, current learner xgboost\n",
      "[flaml.automl.logger: 05-28 12:15:25] {2383} INFO -  at 14.0s,\testimator xgboost's best error=0.1589,\tbest estimator lgbm's best error=0.1388\n",
      "[flaml.automl.logger: 05-28 12:15:25] {2210} INFO - iteration 46, current learner lgbm\n",
      "[flaml.automl.logger: 05-28 12:15:25] {2383} INFO -  at 14.3s,\testimator lgbm's best error=0.1388,\tbest estimator lgbm's best error=0.1388\n",
      "[flaml.automl.logger: 05-28 12:15:25] {2210} INFO - iteration 47, current learner catboost\n",
      "[flaml.automl.logger: 05-28 12:15:51] {2383} INFO -  at 39.7s,\testimator catboost's best error=0.1311,\tbest estimator catboost's best error=0.1311\n",
      "[flaml.automl.logger: 05-28 12:15:51] {2210} INFO - iteration 48, current learner xgboost\n",
      "[flaml.automl.logger: 05-28 12:15:51] {2383} INFO -  at 40.0s,\testimator xgboost's best error=0.1589,\tbest estimator catboost's best error=0.1311\n",
      "[flaml.automl.logger: 05-28 12:15:51] {2210} INFO - iteration 49, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 05-28 12:15:52] {2383} INFO -  at 40.7s,\testimator xgb_limitdepth's best error=0.1429,\tbest estimator catboost's best error=0.1311\n",
      "[flaml.automl.logger: 05-28 12:15:52] {2210} INFO - iteration 50, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 05-28 12:15:52] {2383} INFO -  at 41.2s,\testimator xgb_limitdepth's best error=0.1429,\tbest estimator catboost's best error=0.1311\n",
      "[flaml.automl.logger: 05-28 12:15:52] {2210} INFO - iteration 51, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 05-28 12:15:53] {2383} INFO -  at 41.8s,\testimator xgb_limitdepth's best error=0.1429,\tbest estimator catboost's best error=0.1311\n",
      "[flaml.automl.logger: 05-28 12:15:53] {2210} INFO - iteration 52, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 05-28 12:15:53] {2383} INFO -  at 42.3s,\testimator xgb_limitdepth's best error=0.1429,\tbest estimator catboost's best error=0.1311\n",
      "[flaml.automl.logger: 05-28 12:15:53] {2210} INFO - iteration 53, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 05-28 12:15:54] {2383} INFO -  at 42.9s,\testimator xgb_limitdepth's best error=0.1429,\tbest estimator catboost's best error=0.1311\n",
      "[flaml.automl.logger: 05-28 12:15:54] {2210} INFO - iteration 54, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 05-28 12:15:54] {2383} INFO -  at 43.2s,\testimator xgb_limitdepth's best error=0.1429,\tbest estimator catboost's best error=0.1311\n",
      "[flaml.automl.logger: 05-28 12:15:54] {2210} INFO - iteration 55, current learner catboost\n",
      "[flaml.automl.logger: 05-28 12:16:22] {2383} INFO -  at 71.4s,\testimator catboost's best error=0.1311,\tbest estimator catboost's best error=0.1311\n",
      "[flaml.automl.logger: 05-28 12:16:22] {2210} INFO - iteration 56, current learner lgbm\n",
      "[flaml.automl.logger: 05-28 12:16:23] {2383} INFO -  at 71.9s,\testimator lgbm's best error=0.1388,\tbest estimator catboost's best error=0.1311\n",
      "[flaml.automl.logger: 05-28 12:16:23] {2210} INFO - iteration 57, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 05-28 12:16:25] {2383} INFO -  at 74.0s,\testimator xgb_limitdepth's best error=0.1429,\tbest estimator catboost's best error=0.1311\n",
      "[flaml.automl.logger: 05-28 12:16:25] {2210} INFO - iteration 58, current learner catboost\n",
      "[flaml.automl.logger: 05-28 12:16:50] {2383} INFO -  at 98.9s,\testimator catboost's best error=0.1310,\tbest estimator catboost's best error=0.1310\n",
      "[flaml.automl.logger: 05-28 12:16:50] {2210} INFO - iteration 59, current learner xgboost\n",
      "[flaml.automl.logger: 05-28 12:16:50] {2383} INFO -  at 99.3s,\testimator xgboost's best error=0.1589,\tbest estimator catboost's best error=0.1310\n",
      "[flaml.automl.logger: 05-28 12:16:50] {2210} INFO - iteration 60, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 05-28 12:16:51] {2383} INFO -  at 100.0s,\testimator xgb_limitdepth's best error=0.1429,\tbest estimator catboost's best error=0.1310\n",
      "[flaml.automl.logger: 05-28 12:16:51] {2210} INFO - iteration 61, current learner lgbm\n",
      "[flaml.automl.logger: 05-28 12:16:51] {2383} INFO -  at 100.4s,\testimator lgbm's best error=0.1388,\tbest estimator catboost's best error=0.1310\n",
      "[flaml.automl.logger: 05-28 12:16:51] {2210} INFO - iteration 62, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 05-28 12:16:52] {2383} INFO -  at 100.8s,\testimator xgb_limitdepth's best error=0.1429,\tbest estimator catboost's best error=0.1310\n",
      "[flaml.automl.logger: 05-28 12:16:52] {2210} INFO - iteration 63, current learner rf\n",
      "[flaml.automl.logger: 05-28 12:16:53] {2383} INFO -  at 101.8s,\testimator rf's best error=0.1596,\tbest estimator catboost's best error=0.1310\n",
      "[flaml.automl.logger: 05-28 12:16:53] {2210} INFO - iteration 64, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 05-28 12:16:53] {2383} INFO -  at 102.3s,\testimator xgb_limitdepth's best error=0.1413,\tbest estimator catboost's best error=0.1310\n",
      "[flaml.automl.logger: 05-28 12:16:53] {2210} INFO - iteration 65, current learner xgboost\n",
      "[flaml.automl.logger: 05-28 12:16:54] {2383} INFO -  at 102.6s,\testimator xgboost's best error=0.1533,\tbest estimator catboost's best error=0.1310\n",
      "[flaml.automl.logger: 05-28 12:16:54] {2210} INFO - iteration 66, current learner lgbm\n",
      "[flaml.automl.logger: 05-28 12:16:54] {2383} INFO -  at 102.9s,\testimator lgbm's best error=0.1388,\tbest estimator catboost's best error=0.1310\n",
      "[flaml.automl.logger: 05-28 12:16:54] {2210} INFO - iteration 67, current learner xgboost\n",
      "[flaml.automl.logger: 05-28 12:16:55] {2383} INFO -  at 103.6s,\testimator xgboost's best error=0.1533,\tbest estimator catboost's best error=0.1310\n",
      "[flaml.automl.logger: 05-28 12:16:55] {2210} INFO - iteration 68, current learner xgboost\n",
      "[flaml.automl.logger: 05-28 12:16:55] {2383} INFO -  at 103.9s,\testimator xgboost's best error=0.1533,\tbest estimator catboost's best error=0.1310\n",
      "[flaml.automl.logger: 05-28 12:16:55] {2210} INFO - iteration 69, current learner catboost\n",
      "[flaml.automl.logger: 05-28 12:17:20] {2383} INFO -  at 128.9s,\testimator catboost's best error=0.1310,\tbest estimator catboost's best error=0.1310\n",
      "[flaml.automl.logger: 05-28 12:17:20] {2210} INFO - iteration 70, current learner lgbm\n",
      "[flaml.automl.logger: 05-28 12:17:20] {2383} INFO -  at 129.5s,\testimator lgbm's best error=0.1388,\tbest estimator catboost's best error=0.1310\n",
      "[flaml.automl.logger: 05-28 12:17:20] {2210} INFO - iteration 71, current learner xgboost\n",
      "[flaml.automl.logger: 05-28 12:17:21] {2383} INFO -  at 130.0s,\testimator xgboost's best error=0.1434,\tbest estimator catboost's best error=0.1310\n",
      "[flaml.automl.logger: 05-28 12:17:21] {2210} INFO - iteration 72, current learner xgboost\n",
      "[flaml.automl.logger: 05-28 12:17:21] {2383} INFO -  at 130.4s,\testimator xgboost's best error=0.1434,\tbest estimator catboost's best error=0.1310\n",
      "[flaml.automl.logger: 05-28 12:17:21] {2210} INFO - iteration 73, current learner xgboost\n",
      "[flaml.automl.logger: 05-28 12:17:24] {2383} INFO -  at 132.9s,\testimator xgboost's best error=0.1412,\tbest estimator catboost's best error=0.1310\n",
      "[flaml.automl.logger: 05-28 12:17:24] {2210} INFO - iteration 74, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 05-28 12:17:25] {2383} INFO -  at 133.5s,\testimator xgb_limitdepth's best error=0.1413,\tbest estimator catboost's best error=0.1310\n",
      "[flaml.automl.logger: 05-28 12:17:25] {2210} INFO - iteration 75, current learner xgboost\n",
      "[flaml.automl.logger: 05-28 12:17:25] {2383} INFO -  at 134.0s,\testimator xgboost's best error=0.1412,\tbest estimator catboost's best error=0.1310\n",
      "[flaml.automl.logger: 05-28 12:17:25] {2210} INFO - iteration 76, current learner extra_tree\n",
      "[flaml.automl.logger: 05-28 12:17:26] {2383} INFO -  at 134.6s,\testimator extra_tree's best error=0.1764,\tbest estimator catboost's best error=0.1310\n",
      "[flaml.automl.logger: 05-28 12:17:26] {2210} INFO - iteration 77, current learner rf\n",
      "[flaml.automl.logger: 05-28 12:17:27] {2383} INFO -  at 135.8s,\testimator rf's best error=0.1596,\tbest estimator catboost's best error=0.1310\n",
      "[flaml.automl.logger: 05-28 12:17:27] {2210} INFO - iteration 78, current learner rf\n",
      "[flaml.automl.logger: 05-28 12:17:27] {2383} INFO -  at 136.4s,\testimator rf's best error=0.1596,\tbest estimator catboost's best error=0.1310\n",
      "[flaml.automl.logger: 05-28 12:17:27] {2210} INFO - iteration 79, current learner extra_tree\n",
      "[flaml.automl.logger: 05-28 12:17:28] {2383} INFO -  at 136.6s,\testimator extra_tree's best error=0.1764,\tbest estimator catboost's best error=0.1310\n",
      "[flaml.automl.logger: 05-28 12:17:28] {2210} INFO - iteration 80, current learner xgboost\n",
      "[flaml.automl.logger: 05-28 12:17:28] {2383} INFO -  at 137.3s,\testimator xgboost's best error=0.1412,\tbest estimator catboost's best error=0.1310\n",
      "[flaml.automl.logger: 05-28 12:17:28] {2210} INFO - iteration 81, current learner rf\n",
      "[flaml.automl.logger: 05-28 12:17:29] {2383} INFO -  at 138.1s,\testimator rf's best error=0.1487,\tbest estimator catboost's best error=0.1310\n",
      "[flaml.automl.logger: 05-28 12:17:29] {2210} INFO - iteration 82, current learner extra_tree\n",
      "[flaml.automl.logger: 05-28 12:17:30] {2383} INFO -  at 138.7s,\testimator extra_tree's best error=0.1512,\tbest estimator catboost's best error=0.1310\n",
      "[flaml.automl.logger: 05-28 12:17:30] {2210} INFO - iteration 83, current learner extra_tree\n",
      "[flaml.automl.logger: 05-28 12:17:30] {2383} INFO -  at 139.0s,\testimator extra_tree's best error=0.1512,\tbest estimator catboost's best error=0.1310\n",
      "[flaml.automl.logger: 05-28 12:17:30] {2210} INFO - iteration 84, current learner extra_tree\n",
      "[flaml.automl.logger: 05-28 12:17:31] {2383} INFO -  at 139.6s,\testimator extra_tree's best error=0.1512,\tbest estimator catboost's best error=0.1310\n",
      "[flaml.automl.logger: 05-28 12:17:31] {2210} INFO - iteration 85, current learner extra_tree\n",
      "[flaml.automl.logger: 05-28 12:17:31] {2383} INFO -  at 140.0s,\testimator extra_tree's best error=0.1447,\tbest estimator catboost's best error=0.1310\n",
      "[flaml.automl.logger: 05-28 12:17:31] {2210} INFO - iteration 86, current learner extra_tree\n",
      "[flaml.automl.logger: 05-28 12:17:31] {2383} INFO -  at 140.4s,\testimator extra_tree's best error=0.1447,\tbest estimator catboost's best error=0.1310\n",
      "[flaml.automl.logger: 05-28 12:17:31] {2210} INFO - iteration 87, current learner extra_tree\n",
      "[flaml.automl.logger: 05-28 12:17:32] {2383} INFO -  at 141.0s,\testimator extra_tree's best error=0.1409,\tbest estimator catboost's best error=0.1310\n",
      "[flaml.automl.logger: 05-28 12:17:32] {2210} INFO - iteration 88, current learner extra_tree\n",
      "[flaml.automl.logger: 05-28 12:17:33] {2383} INFO -  at 141.6s,\testimator extra_tree's best error=0.1409,\tbest estimator catboost's best error=0.1310\n",
      "[flaml.automl.logger: 05-28 12:17:33] {2210} INFO - iteration 89, current learner rf\n",
      "[flaml.automl.logger: 05-28 12:17:33] {2383} INFO -  at 142.1s,\testimator rf's best error=0.1487,\tbest estimator catboost's best error=0.1310\n",
      "[flaml.automl.logger: 05-28 12:17:33] {2210} INFO - iteration 90, current learner rf\n",
      "[flaml.automl.logger: 05-28 12:17:34] {2383} INFO -  at 143.0s,\testimator rf's best error=0.1443,\tbest estimator catboost's best error=0.1310\n",
      "[flaml.automl.logger: 05-28 12:17:34] {2210} INFO - iteration 91, current learner extra_tree\n",
      "[flaml.automl.logger: 05-28 12:17:36] {2383} INFO -  at 144.7s,\testimator extra_tree's best error=0.1408,\tbest estimator catboost's best error=0.1310\n",
      "[flaml.automl.logger: 05-28 12:17:36] {2210} INFO - iteration 92, current learner rf\n",
      "[flaml.automl.logger: 05-28 12:17:36] {2383} INFO -  at 145.5s,\testimator rf's best error=0.1443,\tbest estimator catboost's best error=0.1310\n",
      "[flaml.automl.logger: 05-28 12:17:36] {2210} INFO - iteration 93, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 05-28 12:17:37] {2383} INFO -  at 145.9s,\testimator xgb_limitdepth's best error=0.1413,\tbest estimator catboost's best error=0.1310\n",
      "[flaml.automl.logger: 05-28 12:17:37] {2210} INFO - iteration 94, current learner catboost\n",
      "[flaml.automl.logger: 05-28 12:17:55] {2383} INFO -  at 164.2s,\testimator catboost's best error=0.1309,\tbest estimator catboost's best error=0.1309\n",
      "[flaml.automl.logger: 05-28 12:17:55] {2210} INFO - iteration 95, current learner catboost\n",
      "[flaml.automl.logger: 05-28 12:18:14] {2383} INFO -  at 182.9s,\testimator catboost's best error=0.1309,\tbest estimator catboost's best error=0.1309\n",
      "[flaml.automl.logger: 05-28 12:18:14] {2210} INFO - iteration 96, current learner lgbm\n",
      "[flaml.automl.logger: 05-28 12:18:14] {2383} INFO -  at 183.1s,\testimator lgbm's best error=0.1388,\tbest estimator catboost's best error=0.1309\n",
      "[flaml.automl.logger: 05-28 12:18:14] {2210} INFO - iteration 97, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 05-28 12:18:15] {2383} INFO -  at 184.1s,\testimator xgb_limitdepth's best error=0.1413,\tbest estimator catboost's best error=0.1309\n",
      "[flaml.automl.logger: 05-28 12:18:15] {2210} INFO - iteration 98, current learner rf\n",
      "[flaml.automl.logger: 05-28 12:18:17] {2383} INFO -  at 186.3s,\testimator rf's best error=0.1443,\tbest estimator catboost's best error=0.1309\n",
      "[flaml.automl.logger: 05-28 12:18:17] {2210} INFO - iteration 99, current learner rf\n",
      "[flaml.automl.logger: 05-28 12:18:18] {2383} INFO -  at 187.2s,\testimator rf's best error=0.1443,\tbest estimator catboost's best error=0.1309\n",
      "[flaml.automl.logger: 05-28 12:18:18] {2210} INFO - iteration 100, current learner rf\n",
      "[flaml.automl.logger: 05-28 12:18:19] {2383} INFO -  at 188.4s,\testimator rf's best error=0.1443,\tbest estimator catboost's best error=0.1309\n",
      "[flaml.automl.logger: 05-28 12:18:19] {2210} INFO - iteration 101, current learner lrl1\n",
      "[flaml.automl.logger: 05-28 12:18:22] {2383} INFO -  at 190.8s,\testimator lrl1's best error=0.5179,\tbest estimator catboost's best error=0.1309\n",
      "[flaml.automl.logger: 05-28 12:18:22] {2210} INFO - iteration 102, current learner lrl1\n",
      "[flaml.automl.logger: 05-28 12:18:24] {2383} INFO -  at 192.8s,\testimator lrl1's best error=0.5179,\tbest estimator catboost's best error=0.1309\n",
      "[flaml.automl.logger: 05-28 12:18:24] {2210} INFO - iteration 103, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 05-28 12:18:24] {2383} INFO -  at 193.2s,\testimator xgb_limitdepth's best error=0.1413,\tbest estimator catboost's best error=0.1309\n",
      "[flaml.automl.logger: 05-28 12:18:24] {2210} INFO - iteration 104, current learner xgboost\n",
      "[flaml.automl.logger: 05-28 12:18:26] {2383} INFO -  at 194.8s,\testimator xgboost's best error=0.1412,\tbest estimator catboost's best error=0.1309\n",
      "[flaml.automl.logger: 05-28 12:18:26] {2210} INFO - iteration 105, current learner lgbm\n",
      "[flaml.automl.logger: 05-28 12:18:26] {2383} INFO -  at 195.5s,\testimator lgbm's best error=0.1388,\tbest estimator catboost's best error=0.1309\n",
      "[flaml.automl.logger: 05-28 12:18:26] {2210} INFO - iteration 106, current learner xgboost\n",
      "[flaml.automl.logger: 05-28 12:18:29] {2383} INFO -  at 197.9s,\testimator xgboost's best error=0.1412,\tbest estimator catboost's best error=0.1309\n",
      "[flaml.automl.logger: 05-28 12:18:29] {2210} INFO - iteration 107, current learner rf\n",
      "[flaml.automl.logger: 05-28 12:18:30] {2383} INFO -  at 199.2s,\testimator rf's best error=0.1443,\tbest estimator catboost's best error=0.1309\n",
      "[flaml.automl.logger: 05-28 12:18:30] {2210} INFO - iteration 108, current learner lgbm\n",
      "[flaml.automl.logger: 05-28 12:18:31] {2383} INFO -  at 200.0s,\testimator lgbm's best error=0.1388,\tbest estimator catboost's best error=0.1309\n",
      "[flaml.automl.logger: 05-28 12:18:34] {2619} INFO - retrain catboost for 3.2s\n",
      "[flaml.automl.logger: 05-28 12:18:34] {2622} INFO - retrained model: <catboost.core.CatBoostClassifier object at 0x000001CC46D050F0>\n",
      "[flaml.automl.logger: 05-28 12:18:34] {1930} INFO - fit succeeded\n",
      "[flaml.automl.logger: 05-28 12:18:34] {1931} INFO - Time taken to find the best model: 164.20165157318115\n"
     ]
    }
   ],
   "source": [
    "automl.fit(X_train=X_train, y_train=y_train, dataframe=data_loader, **automl_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<flaml.automl.model.CatBoostEstimator object at 0x000001CC4978CE80>\n",
      "0.13090579979670405\n"
     ]
    }
   ],
   "source": [
    "best_model = automl.model\n",
    "best_score = automl.best_loss\n",
    "print(best_model)\n",
    "print(best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ML leaner: catboost\n",
      "Best hyperparmeter config: {'early_stopping_rounds': 10, 'learning_rate': 0.2, 'n_estimators': 47}\n",
      "Best accuracy on validation data: 0.8691\n",
      "Training duration of best run: 3.249 s\n"
     ]
    }
   ],
   "source": [
    "'''retrieve best config and best learner'''\n",
    "print('Best ML leaner:', automl.best_estimator)\n",
    "print('Best hyperparmeter config:', automl.best_config)\n",
    "print('Best accuracy on validation data: {0:.4g}'.format(1-automl.best_loss))\n",
    "print('Training duration of best run: {0:.4g} s'.format(automl.best_config_train_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x1cc46d050f0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automl.model.estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Current Learner': 'lgbm', 'Current Sample': 7893, 'Current Hyper-parameters': {'n_estimators': 4, 'num_leaves': 4, 'min_child_samples': 20, 'learning_rate': 0.09999999999999995, 'log_max_bin': 8, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.0}, 'Best Learner': 'lgbm', 'Best Hyper-parameters': {'n_estimators': 4, 'num_leaves': 4, 'min_child_samples': 20, 'learning_rate': 0.09999999999999995, 'log_max_bin': 8, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.0}}\n",
      "{'Current Learner': 'lgbm', 'Current Sample': 7893, 'Current Hyper-parameters': {'n_estimators': 4, 'num_leaves': 4, 'min_child_samples': 12, 'learning_rate': 0.26770501231052046, 'log_max_bin': 7, 'colsample_bytree': 1.0, 'reg_alpha': 0.001348364934537134, 'reg_lambda': 1.4442580148221913}, 'Best Learner': 'lgbm', 'Best Hyper-parameters': {'n_estimators': 4, 'num_leaves': 4, 'min_child_samples': 12, 'learning_rate': 0.26770501231052046, 'log_max_bin': 7, 'colsample_bytree': 1.0, 'reg_alpha': 0.001348364934537134, 'reg_lambda': 1.4442580148221913}}\n",
      "{'Current Learner': 'lgbm', 'Current Sample': 7893, 'Current Hyper-parameters': {'n_estimators': 10, 'num_leaves': 4, 'min_child_samples': 9, 'learning_rate': 0.7260594590615893, 'log_max_bin': 9, 'colsample_bytree': 0.9285002286474459, 'reg_alpha': 0.0036840681931986645, 'reg_lambda': 0.7532480505730402}, 'Best Learner': 'lgbm', 'Best Hyper-parameters': {'n_estimators': 10, 'num_leaves': 4, 'min_child_samples': 9, 'learning_rate': 0.7260594590615893, 'log_max_bin': 9, 'colsample_bytree': 0.9285002286474459, 'reg_alpha': 0.0036840681931986645, 'reg_lambda': 0.7532480505730402}}\n",
      "{'Current Learner': 'lgbm', 'Current Sample': 7893, 'Current Hyper-parameters': {'n_estimators': 11, 'num_leaves': 5, 'min_child_samples': 5, 'learning_rate': 0.7590459488450945, 'log_max_bin': 8, 'colsample_bytree': 0.8304072431299575, 'reg_alpha': 0.001951378031519758, 'reg_lambda': 0.04792552866398477}, 'Best Learner': 'lgbm', 'Best Hyper-parameters': {'n_estimators': 11, 'num_leaves': 5, 'min_child_samples': 5, 'learning_rate': 0.7590459488450945, 'log_max_bin': 8, 'colsample_bytree': 0.8304072431299575, 'reg_alpha': 0.001951378031519758, 'reg_lambda': 0.04792552866398477}}\n",
      "{'Current Learner': 'lgbm', 'Current Sample': 7893, 'Current Hyper-parameters': {'n_estimators': 34, 'num_leaves': 4, 'min_child_samples': 4, 'learning_rate': 0.41929025492645006, 'log_max_bin': 8, 'colsample_bytree': 0.7610534336273627, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.00928065500587993}, 'Best Learner': 'lgbm', 'Best Hyper-parameters': {'n_estimators': 34, 'num_leaves': 4, 'min_child_samples': 4, 'learning_rate': 0.41929025492645006, 'log_max_bin': 8, 'colsample_bytree': 0.7610534336273627, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.00928065500587993}}\n",
      "{'Current Learner': 'lgbm', 'Current Sample': 7893, 'Current Hyper-parameters': {'n_estimators': 22, 'num_leaves': 15, 'min_child_samples': 5, 'learning_rate': 0.22524994995743033, 'log_max_bin': 7, 'colsample_bytree': 0.6929232362522451, 'reg_alpha': 0.006958608037974516, 'reg_lambda': 0.002602283101242092}, 'Best Learner': 'lgbm', 'Best Hyper-parameters': {'n_estimators': 22, 'num_leaves': 15, 'min_child_samples': 5, 'learning_rate': 0.22524994995743033, 'log_max_bin': 7, 'colsample_bytree': 0.6929232362522451, 'reg_alpha': 0.006958608037974516, 'reg_lambda': 0.002602283101242092}}\n",
      "{'Current Learner': 'catboost', 'Current Sample': 7893, 'Current Hyper-parameters': {'early_stopping_rounds': 10, 'learning_rate': 0.09999999999999996, 'n_estimators': 89}, 'Best Learner': 'catboost', 'Best Hyper-parameters': {'early_stopping_rounds': 10, 'learning_rate': 0.09999999999999996, 'n_estimators': 89}}\n",
      "{'Current Learner': 'catboost', 'Current Sample': 7893, 'Current Hyper-parameters': {'early_stopping_rounds': 12, 'learning_rate': 0.1604199347807429, 'n_estimators': 63}, 'Best Learner': 'catboost', 'Best Hyper-parameters': {'early_stopping_rounds': 12, 'learning_rate': 0.1604199347807429, 'n_estimators': 63}}\n",
      "{'Current Learner': 'catboost', 'Current Sample': 7893, 'Current Hyper-parameters': {'early_stopping_rounds': 10, 'learning_rate': 0.2, 'n_estimators': 47}, 'Best Learner': 'catboost', 'Best Hyper-parameters': {'early_stopping_rounds': 10, 'learning_rate': 0.2, 'n_estimators': 47}}\n"
     ]
    }
   ],
   "source": [
    "from flaml.data import get_output_from_log\n",
    "time_history, best_valid_loss_history, valid_loss_history, config_history, metric_history = \\\n",
    "    get_output_from_log(filename=automl_settings['log_file_name'], time_budget=240)\n",
    "for config in config_history:\n",
    "    print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.title('Learning Curve')\n",
    "plt.xlabel('Wall Clock Time (s)')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "plt.scatter(time_history, 1 - np.array(valid_loss_history))\n",
    "plt.step(time_history, 1 - np.array(best_valid_loss_history), where='post')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
